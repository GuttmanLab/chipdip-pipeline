{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5c3111",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e74481-8fb0-405f-864d-624ec0a5da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import gzip\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits.axes_grid1\n",
    "import seaborn as sns\n",
    "\n",
    "import yaml\n",
    "from IPython.display import Image, display\n",
    "from tqdm.auto import tqdm\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8248d63c",
   "metadata": {},
   "source": [
    "Set up directory paths\n",
    "- The \"input directory\" refers to where your configuration files (especially `config.yaml`) are located. See the [ChIP-DIP GitHub repository](https://github.com/GuttmanLab/chipdip-pipeline) for more information.\n",
    "- The provided paths below assume that (1) this notebook is launched from the \"input directory,\" and (2) the \"working directory\" for the pipeline (where Snakemake was launched) is the same as the \"input directory.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify these paths as necessary/desired\n",
    "DIR_INPUT = os.getcwd()\n",
    "DIR_ANALYSIS = os.path.join(DIR_INPUT, 'analysis') # for analysis files, such as CSV and NumPy .npy files\n",
    "DIR_FIGURES = os.path.join(DIR_ANALYSIS, 'figures') # for figures\n",
    "os.makedirs(DIR_FIGURES, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f92e52",
   "metadata": {},
   "source": [
    "Load sample and pipeline configuration information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DIR_INPUT, 'config', 'config.yaml')) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "if os.path.isabs(config['samples']):\n",
    "    path_samples = config['samples']\n",
    "else:\n",
    "    path_samples = os.path.join(DIR_INPUT, config['samples'])\n",
    "with open(path_samples, 'r') as f:\n",
    "    samples = tuple(json.load(f).keys())\n",
    "\n",
    "if os.path.isabs(config['output_dir']):\n",
    "    DIR_WORKUP = config['output_dir']\n",
    "else:\n",
    "    DIR_WORKUP = os.path.join(DIR_INPUT, config['output_dir'])\n",
    "\n",
    "max_chromatin_cluster_size = config.get('max_size', 10000)\n",
    "min_oligos = config.get('min_oligos', 2)\n",
    "proportion = config.get('proportion', 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f38ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pipeline scripts directory to path to be able to import custom modules\n",
    "sys.path.append(os.path.join(config['scripts_dir'], 'python'))\n",
    "from clusters_to_interaction import label_counts_to_interaction_chunked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a693e14d",
   "metadata": {},
   "source": [
    "Number of processes to use for parallel computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f530f89c-87bc-4819-85f1-09d8e213ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_processes = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c847028c",
   "metadata": {},
   "source": [
    "## Analysis output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_out = lambda key: os.path.join(DIR_ANALYSIS, key + '.csv')\n",
    "figs_out = lambda key: os.path.join(DIR_FIGURES, key + '.png')\n",
    "paths_out = {\n",
    "    'label_distribution': os.path.join(DIR_ANALYSIS, 'label_distribution.json.gz'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56209842-a850-462f-9d3f-6aea48152797",
   "metadata": {},
   "source": [
    "# Sequencing QC and Pipeline Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d7698c-26f2-4681-ade7-d3c8562fc8b7",
   "metadata": {},
   "source": [
    "Read counts for entire sequencing run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d30186",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_metrics = pd.read_csv(os.path.join(DIR_WORKUP, 'qc', 'pipeline_counts.csv'), index_col=0)\n",
    "pipeline_metrics['name'] = pipeline_metrics['depth'].map(lambda x: '  ' * max(x, 0) + '- ' * min(x, 1)) + pipeline_metrics['level']\n",
    "pipeline_metrics[['sample', 'name', 'n_reads', 'frac_parent', 'frac_base', 'frac_root']] \\\n",
    "    .style.set_properties(**{\n",
    "        'text-align': 'left',\n",
    "        'font-family': 'Consolas',\n",
    "        'white-space': 'pre'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_counts = pipeline_metrics.set_index(['sample', 'level'])['n_reads'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280c8d69",
   "metadata": {},
   "source": [
    "## PCR Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b4c73f",
   "metadata": {},
   "source": [
    "Estimate library complexity based on Poisson model [[notes]](https://github.com/bentyeh/resources/blob/main/bioinformatics/models_genomics.md#general-library-preparation-and-sequencing-considerations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplication = read_counts.loc[(slice(None), ['extract_barcode_to_tags', 'merge_dpm', 'bpm_fastq_to_bam', 'merge_bpm'])].to_frame()\n",
    "df_duplication['description'] = df_duplication.index.get_level_values(1).map({\n",
    "    'extract_barcode_to_tags': 'Number of filtered chromatin reads',\n",
    "    'merge_dpm': 'Number of filtered deduplicated chromatin reads',\n",
    "    'bpm_fastq_to_bam': 'Number of oligo reads',\n",
    "    'merge_bpm': 'Number of deduplicated oligo reads',\n",
    "})\n",
    "df_duplication = df_duplication.reset_index().rename(columns={'n_reads': 'value'}).drop(columns='level')\n",
    "df_duplication['molecule type'] = df_duplication['description'].str.extract('(oligo|chromatin)')\n",
    "df_duplication['deduplication'] = df_duplication['description'].map(lambda s: 'deduplicated' if 'deduplicated' in s else 'none')\n",
    "df_duplication = pd.concat(\n",
    "    (\n",
    "        df_duplication,\n",
    "        (\n",
    "            df_duplication\n",
    "            .groupby(['sample', 'molecule type'])[['deduplication', 'value']] \\\n",
    "            .apply(\n",
    "                lambda group:\n",
    "                    1 - group.loc[group['deduplication'] == 'deduplicated', 'value'].item() /\n",
    "                        group.loc[group['deduplication'] == 'none', 'value'].item()\n",
    "            )\n",
    "            .rename('value')\n",
    "            .to_frame()\n",
    "            .reset_index()\n",
    "            .pipe(lambda df: df.assign(description='Proportion of ' + df['molecule type'] + ' reads that are duplicates'))\n",
    "        )\n",
    "    ),\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for sample in list(samples) + ['all']:\n",
    "    count_chromatin_reads = read_counts.loc[(sample, 'extract_barcode_to_tags')]\n",
    "    count_chromatin_dedup = read_counts.loc[(sample, 'merge_dpm')]\n",
    "    res_chromatin = scipy.optimize.minimize_scalar(\n",
    "        fun=lambda M: (M * (1 - np.exp(-count_chromatin_reads/M)) - count_chromatin_dedup)**2,\n",
    "        bracket=(count_chromatin_dedup, count_chromatin_reads))\n",
    "    assert res_chromatin.success and res_chromatin.fun < 1e-3 and res_chromatin.x > count_chromatin_dedup\n",
    "    results.append(dict(sample=sample, value=res_chromatin.x, description='Estimated chromatin library complexity'))\n",
    "\n",
    "    count_oligo_reads = read_counts.loc[(sample, 'bpm_fastq_to_bam')]\n",
    "    count_oligo_dedup = read_counts.loc[(sample, 'merge_bpm')]\n",
    "    res_oligo = scipy.optimize.minimize_scalar(\n",
    "        fun=lambda M: (M * (1 - np.exp(-count_oligo_reads/M)) - count_oligo_dedup)**2,\n",
    "        bracket=(count_oligo_dedup, count_oligo_reads))\n",
    "    assert res_oligo.success and res_oligo.fun < 1e-3 and res_oligo.x > count_oligo_dedup\n",
    "    results.append(dict(sample=sample, value=res_oligo.x, description='Estimated oligo library complexity'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplication = pd.concat((df_duplication, pd.DataFrame(results)), axis=0) \\\n",
    "    .pivot(index='description', columns='sample', values='value')\n",
    "display(df_duplication.loc[[\n",
    "    'Number of filtered chromatin reads',\n",
    "    'Number of filtered deduplicated chromatin reads',\n",
    "    'Proportion of chromatin reads that are duplicates',\n",
    "    'Estimated chromatin library complexity'\n",
    "]].style.format('{:g}'))\n",
    "display(df_duplication.loc[[\n",
    "    'Number of oligo reads',\n",
    "    'Number of deduplicated oligo reads',\n",
    "    'Proportion of oligo reads that are duplicates',\n",
    "    'Estimated oligo library complexity'\n",
    "]].style.format('{:g}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74999f7-1f74-4ee1-b810-6a61fa306034",
   "metadata": {},
   "source": [
    "## Split-BAM Read Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190c5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(csv_out('splitbams_counts')):\n",
    "    regex_splitbam_path = r'^(?:(?:(?P<sample>[^.]+)\\.)?(?P<target>[^.]+))\\.bam$'\n",
    "    df_splitbams = pd.read_csv(\n",
    "        os.path.join(DIR_WORKUP, 'splitbams', 'splitbam_counts.txt'),\n",
    "        sep='\\t',\n",
    "        names=['path', 'chromatin count']\n",
    "    )\n",
    "    df_splitbams = pd.concat(\n",
    "        (\n",
    "            df_splitbams,\n",
    "            df_splitbams['path'].map(lambda s: os.path.basename(s)).str.extract(regex_splitbam_path, expand=True)\n",
    "        ),\n",
    "        axis=1\n",
    "    ).drop(columns='path')\n",
    "    df_splitbams['sample'] = df_splitbams['sample'].fillna('all')\n",
    "    df_splitbams = (\n",
    "        df_splitbams\n",
    "        .groupby('sample', group_keys=False)[df_splitbams.columns]\n",
    "        .apply(lambda df: df.assign(**{'proportion of sample chromatin count': df['chromatin count'] / df['chromatin count'].sum()}))\n",
    "        .pivot_table(index='target', columns='sample')\n",
    "    )\n",
    "    df_splitbams.to_csv(csv_out('splitbams_counts'))\n",
    "    display(df_splitbams.sort_values(('proportion of sample chromatin count', 'all'), ascending=False))\n",
    "else:\n",
    "    df_splitbams = pd.read_csv(csv_out('splitbams_counts'), index_col=0, header=[0, 1])\n",
    "    display(df_splitbams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb4ca91",
   "metadata": {},
   "source": [
    "Proportion of deduplicated chromatin reads resolved to targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    (\n",
    "        df_splitbams.loc[~df_splitbams.index.isin(['uncertain', 'none', 'ambiguous', 'filtered'])] \\\n",
    "            .sum(axis=0).rename('resolved to targets'),\n",
    "        df_splitbams.sum(axis=0).rename('deduplicated chromatin reads')\n",
    "    ),\n",
    "    axis=1\n",
    ").T.astype({col: int for col in df_splitbams.columns[df_splitbams.columns.get_level_values(0) == 'chromatin count']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0d1a7",
   "metadata": {},
   "source": [
    "# Overall efficiency\n",
    "\n",
    "Proportion of all reads represented by target-resolved chromatin and deduplicated oligos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78670e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    (\n",
    "        read_counts.loc[(slice(None), 'compress_fastq')].rename('total read count'),\n",
    "        read_counts.loc[(slice(None), 'merge_bpm')].rename('deduplicated oligo count'),\n",
    "        df_splitbams.loc[\n",
    "            ~df_splitbams.index.isin(['uncertain', 'none', 'ambiguous', 'filtered']),\n",
    "            ('chromatin count', slice(None))\n",
    "        ].droplevel(0, axis=1).sum(axis=0).rename('target-resolved chromatin count')\n",
    "    ),\n",
    "    axis=1\n",
    ").pipe(lambda df: df.assign(**{\n",
    "    'overall efficiency (chromatin only)': df['target-resolved chromatin count'] / df['total read count'],\n",
    "    'overall efficiency (chromatin + oligo)': (df['target-resolved chromatin count'] + df['deduplicated oligo count']) / df['total read count']\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9a89c7-cf2d-447e-9e47-effc199b9a8f",
   "metadata": {},
   "source": [
    "# Clusters Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = 'all' # choose a sample to analyze\n",
    "reprocess = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad0c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE == 'all':\n",
    "    df_reads_per_cluster = pd.concat(\n",
    "        [\n",
    "            pd.read_csv(os.path.join(DIR_WORKUP, \"clusters\", f\"{sample}.stats_reads_per_cluster.tsv.gz\"), sep='\\t').assign(sample=sample)\n",
    "            for sample in samples\n",
    "        ],\n",
    "        axis=0,\n",
    "        ignore_index=True\n",
    "    ).groupby(['antibody ID', 'read type', 'reads per cluster'], group_keys=False)['number of clusters'].sum().reset_index()\n",
    "else:\n",
    "    df_reads_per_cluster = pd.read_csv(os.path.join(DIR_WORKUP, \"clusters\", f\"{SAMPLE}.stats_reads_per_cluster.tsv.gz\"), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e579935",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = df_reads_per_cluster.loc[df_reads_per_cluster['read type'] == 'total', 'number of clusters'].sum()\n",
    "count_oligo_in_clusters = df_reads_per_cluster.loc[df_reads_per_cluster['read type'] == 'BPM'].assign(n_reads=lambda tb: tb['number of clusters'] * tb['reads per cluster'])['n_reads'].sum()\n",
    "count_chromatin_in_clusters = df_reads_per_cluster.loc[df_reads_per_cluster['read type'] == 'DPM'].assign(n_reads=lambda tb: tb['number of clusters'] * tb['reads per cluster'])['n_reads'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aefdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series({\n",
    "    'Number of clusters:': n_clusters,\n",
    "    'Number of oligos:': count_oligo_in_clusters,\n",
    "    'Number of chromatin:': count_chromatin_in_clusters,\n",
    "    'Number of clusters without oligos':\n",
    "        df_reads_per_cluster.loc[\n",
    "            (df_reads_per_cluster['reads per cluster'] == 0) & (df_reads_per_cluster['read type'] == 'BPM'),\n",
    "            'number of clusters'\n",
    "        ].item(),\n",
    "    'Number of clusters without chromatin reads':\n",
    "        df_reads_per_cluster.loc[\n",
    "            (df_reads_per_cluster['reads per cluster'] == 0) & (df_reads_per_cluster['read type'] == 'DPM'),\n",
    "            'number of clusters'\n",
    "        ].sum(),\n",
    "    'Number of clusters with chromatin and oligo reads': \n",
    "        df_reads_per_cluster.loc[\n",
    "            (df_reads_per_cluster['read type'] == 'DPM') & (df_reads_per_cluster['reads per cluster'] > 0) & (df_reads_per_cluster['antibody ID'] != 'none'),\n",
    "            'number of clusters'\n",
    "        ].sum()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148ff3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary_template = {\n",
    "    'chromatin count': 0,\n",
    "    'oligo count': 0,\n",
    "    'mode oligo count': 0,\n",
    "    'label': None\n",
    "}\n",
    "\n",
    "def load_clusters(path_clusters: str) -> tuple[dict[str, dict[str, int]], dict[str, dict[str, int]]]:\n",
    "    '''\n",
    "    Arg\n",
    "    - path_clusters: Path to cluster BAM file\n",
    "\n",
    "    Returns\n",
    "    - clusters_summaries: Map from barcode to cluster summary (dict of 'chromatin count', 'oligo count', 'mode oligo count', 'label')\n",
    "    - label_distribution: Map from barcode to cluster oligo counts\n",
    "    '''\n",
    "    clusters_summaries = {}\n",
    "    label_distribution = {}\n",
    "    with pysam.AlignmentFile(path_clusters, 'r', check_sq=False) as f:\n",
    "        for barcode, reads in itertools.groupby(\n",
    "            tqdm(f.fetch(until_eof=True)),\n",
    "            key=lambda read: read.get_tag('CB')\n",
    "        ):\n",
    "            n_DPM_reads = 0\n",
    "            n_skipped = 0\n",
    "            antibody_IDs_counter = collections.Counter()\n",
    "            for read in reads:\n",
    "                read_type = read.get_tag('RT')\n",
    "                if not isinstance(read_type, str):\n",
    "                    print(f\"Unexpected read type: {read_type}\", file=sys.stderr)\n",
    "                    n_skipped += 1\n",
    "                    continue\n",
    "                if read_type.startswith(\"DPM\"):\n",
    "                    n_DPM_reads += 1\n",
    "                elif read_type.startswith(\"BEAD_\"):\n",
    "                    antibody_IDs_counter[read_type[5:]] += 1\n",
    "                else:\n",
    "                    print(f\"Unexpected read type: {read_type}\", file=sys.stderr)\n",
    "                    n_skipped += 1\n",
    "            total = antibody_IDs_counter.total()\n",
    "            if total == 0:\n",
    "                cluster_summary = {\n",
    "                    'label': None,\n",
    "                    'chromatin count': n_DPM_reads,\n",
    "                    'oligo count': 0,\n",
    "                    'mode oligo count': 0,\n",
    "                }\n",
    "                label_distribution[barcode] = {}\n",
    "            else:\n",
    "                label_distribution[barcode] = antibody_IDs_counter\n",
    "                candidate, count = antibody_IDs_counter.most_common()[0]\n",
    "                if n_DPM_reads > max_chromatin_cluster_size:\n",
    "                    label = \"filtered\"\n",
    "                else:\n",
    "                    if count < min_oligos:\n",
    "                        label = \"uncertain\"\n",
    "                    elif count / total < proportion:\n",
    "                        label = \"ambiguous\"\n",
    "                    else:\n",
    "                        label = candidate\n",
    "                cluster_summary = {\n",
    "                    'label': label,\n",
    "                    'chromatin count': n_DPM_reads,\n",
    "                    'oligo count': total,\n",
    "                    'mode oligo count': count,\n",
    "                }\n",
    "\n",
    "            clusters_summaries[barcode] = cluster_summary\n",
    "    return clusters_summaries, label_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028cff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(csv_out('clusters_summaries')) or not os.path.exists(paths_out['label_distribution']) or reprocess:\n",
    "    path_clusters = os.path.join(DIR_WORKUP, 'clusters', f'{SAMPLE}.labeled.bam' if SAMPLE != 'all' else f'all.bam')\n",
    "    clusters_summaries, label_distribution = load_clusters(path_clusters)\n",
    "    df_clusters = pd.DataFrame.from_dict(clusters_summaries, orient='index')\n",
    "    df_clusters.to_csv(csv_out('clusters_summaries'))\n",
    "    with gzip.open(paths_out['label_distribution'], 'wt') as f:\n",
    "        json.dump(label_distribution, f)\n",
    "else:\n",
    "    df_clusters = pd.read_csv(csv_out('clusters_summaries'), index_col=0)\n",
    "    with gzip.open(paths_out['label_distribution'], 'rt') as f:\n",
    "        label_distribution = json.load(f)\n",
    "df_clusters['mode oligo proportion'] = (df_clusters['mode oligo count'] / df_clusters['oligo count']).fillna(0)\n",
    "df_clusters_with_oligo = df_clusters.loc[df_clusters['oligo count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9be3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert count_chromatin_in_clusters == df_clusters['chromatin count'].sum()\n",
    "assert count_oligo_in_clusters == df_clusters['oligo count'].sum()\n",
    "assert n_clusters == len(df_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6658aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters_long = df_clusters \\\n",
    "    .reset_index(names='barcode') \\\n",
    "    .melt(id_vars=['barcode', 'label'], value_vars=['chromatin count', 'oligo count', 'mode oligo count'], value_name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9313cd-5152-4503-9483-235213975c42",
   "metadata": {},
   "source": [
    "## Counts per target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d263622-3178-4688-b911-e7b4adc61d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(csv_out('counts_per_target')) or reprocess:\n",
    "    df_counts_per_target = (\n",
    "        df_reads_per_cluster\n",
    "        .groupby('antibody ID')[df_reads_per_cluster.columns]\n",
    "        .apply(\n",
    "            lambda g: pd.Series({\n",
    "                'cluster count': g.loc[g['read type'] == 'total', 'number of clusters'].sum(),\n",
    "                'chromatin count': g.loc[g['read type'] == 'DPM'].pipe(lambda tb: tb['number of clusters'] * tb['reads per cluster']).sum(),\n",
    "                'oligo count': g.loc[g['read type'] == 'BPM'].pipe(lambda tb: tb['number of clusters'] * tb['reads per cluster']).sum(),\n",
    "            })\n",
    "        )\n",
    "        .assign(**{\n",
    "            'oligos per cluster': lambda tb: tb['oligo count'] / tb['cluster count'],\n",
    "            'chromatin per cluster': lambda tb: tb['chromatin count'] / tb['cluster count'],\n",
    "            'oligo well': lambda tb: [(s[0] + '0' + s[1]) if len(s) == 2 else s for s in tb.index.str.extract('([^-]+)$').squeeze().values]\n",
    "        })\n",
    "        .infer_objects()\n",
    "        .rename_axis(index='label')\n",
    "    )\n",
    "    df_counts_per_target.to_csv(csv_out('counts_per_target'))\n",
    "else:\n",
    "    df_counts_per_target = pd.read_csv(csv_out('counts_per_target'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c1bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_per_target.sort_values('chromatin per cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d51143-9b00-4699-9164-d3b0c15f5ce5",
   "metadata": {},
   "source": [
    "Check if the resolved clusters are evenly distributed among the input beads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_order = {label: i for i, label in enumerate(df_counts_per_target['cluster count'].sort_values().index)}\n",
    "unlabeled_targets = sorted([x for x in ['ambiguous', 'none', 'uncertain', 'filtered'] if x in label_order], key=lambda s: label_order[s])\n",
    "labeled_targets = [label for label in label_order if label not in unlabeled_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('counts_per_cluster')) or reprocess:\n",
    "    with sns.axes_style('darkgrid'):    \n",
    "        g = sns.FacetGrid(\n",
    "            data=df_clusters[['label', 'chromatin count', 'oligo count', 'mode oligo proportion']] \\\n",
    "                .pipe(lambda df: df.assign(labeled=df['label'].isin(labeled_targets))) \\\n",
    "                .melt(id_vars=['label', 'labeled'], var_name='metric') \\\n",
    "                .sort_values('label', key=lambda series: series.map(label_order)),\n",
    "            col='metric',\n",
    "            row='labeled',\n",
    "            sharex=False,\n",
    "            sharey='row',\n",
    "            gridspec_kws=dict(height_ratios=(0.12, 0.88)),\n",
    "            margin_titles=True\n",
    "        )\n",
    "        g.map_dataframe(\n",
    "            sns.boxplot,\n",
    "            y='label',\n",
    "            x='value',\n",
    "            color='C0',\n",
    "            showfliers=False)\n",
    "        g.set_titles(col_template=\"{col_name}\", row_template='')\n",
    "        g.set_axis_labels('', '')\n",
    "        g.figure.set_size_inches(12, 7)\n",
    "        for (row_val, col_val), ax in g.axes_dict.items():\n",
    "            ax.yaxis.grid(True)\n",
    "            if row_val == False and col_val.endswith('count'):\n",
    "                ax.set_xscale('symlog')\n",
    "        g.figure.text(\n",
    "            0.1,\n",
    "            0,\n",
    "            'Note: The x-axis is symlog-scaled for \"chromatin count\" and \"oligo count\" in the top row.',\n",
    "            horizontalalignment='left')\n",
    "        g.savefig(figs_out('counts_per_cluster'))\n",
    "else:\n",
    "    display(Image(filename=figs_out('counts_per_cluster')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cefb75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('counts_per_target')) or reprocess:\n",
    "    df_plot_counts_per_target = df_counts_per_target \\\n",
    "        .assign(labeled=df_counts_per_target.index.isin(labeled_targets)) \\\n",
    "        .reset_index() \\\n",
    "        .sort_values('cluster count') \\\n",
    "        .drop(columns=['oligo well']) \\\n",
    "        .melt(id_vars=['label', 'labeled'], var_name='metric')\n",
    "\n",
    "    with sns.axes_style('darkgrid'):\n",
    "        g = sns.FacetGrid(\n",
    "            data=df_plot_counts_per_target,\n",
    "            col='metric',\n",
    "            row='labeled',\n",
    "            sharex=False,\n",
    "            sharey='row',\n",
    "            gridspec_kws=dict(height_ratios=(0.12, 0.88)),\n",
    "            margin_titles=True\n",
    "        )\n",
    "        g.map_dataframe(sns.barplot, y='label', x='value', color='C0')\n",
    "        g.set_titles(col_template=\"{col_name}\", row_template='')\n",
    "        g.set_axis_labels('', '')\n",
    "        g.figure.set_size_inches(15, 7)\n",
    "        for (row_val, col_val), ax in g.axes_dict.items():\n",
    "            if row_val == False:\n",
    "                ax.set_xscale('log')\n",
    "        [ax.yaxis.grid(True) for ax in g.axes.flatten()]\n",
    "        g.figure.text(\n",
    "            0.025,\n",
    "            0,\n",
    "            'Note: The x-axis is log-scaled for the top row of unlabeled clusters.')\n",
    "        g.tight_layout()\n",
    "        g.savefig(figs_out('counts_per_target'))\n",
    "else:\n",
    "    display(Image(filename=figs_out('counts_per_target')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc0030-d98c-456b-a07c-840999c82ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_per_target.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cd9272-d4a0-4f83-b9a3-951743814f34",
   "metadata": {},
   "source": [
    "Note that the \"number of oligo reads\" above (in the summary statistics and in the plots) are not the number of oligo reads matching the assigned label, but the total number of oligo reads in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92db71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts_per_target[['cluster count', 'chromatin count', 'oligo count']] \\\n",
    "    .rename(columns=lambda s: s.replace(' count', '')) \\\n",
    "    .melt(value_name='count', ignore_index=False) \\\n",
    "    .pipe(lambda df: df.assign(proportion=df['count'] / df.groupby('variable')['count'].transform('sum'))) \\\n",
    "    .pivot(columns='variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c3a0b",
   "metadata": {},
   "source": [
    "## Cluster distributions: molecules per cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ae9e78",
   "metadata": {},
   "source": [
    "Distributions of molecule counts per cluster, facetted by target (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318612cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all(map(os.path.exists, (figs_out('molecules_per_cluster_unlabeled'), figs_out('molecules_per_cluster_unlabeled_zoom')))) or reprocess:\n",
    "    g = sns.FacetGrid(\n",
    "        data=pd.concat(\n",
    "            (df_clusters_long.loc[df_clusters_long['label'].isin(unlabeled_targets)],\n",
    "             df_clusters_long.loc[df_clusters_long['label'].isin(labeled_targets)].assign(label='labeled')),\n",
    "            axis=0,\n",
    "            ignore_index=True),\n",
    "        hue='variable',\n",
    "        col='label',\n",
    "        height=2.5,\n",
    "        col_order=['labeled'] + unlabeled_targets,\n",
    "        sharex=False\n",
    "    )\n",
    "    g.figure.set_constrained_layout(True)\n",
    "    g.figure.suptitle('Distribution of molecule counts per unlabeled cluster')\n",
    "    g.map(sns.ecdfplot, 'count')\n",
    "    g.add_legend()\n",
    "    g.savefig(figs_out('molecules_per_cluster_unlabeled'))\n",
    "    display(g.figure)\n",
    "\n",
    "    zoom_count_max = 15\n",
    "    [ax.set(xlim=(-0.5, zoom_count_max + 0.5)) for ax in g.axes.flatten()]\n",
    "    g.figure.suptitle('Distribution of molecule counts per unlabeled cluster (zoom)')\n",
    "    g.savefig(figs_out('molecules_per_cluster_unlabeled_zoom'))\n",
    "    g.figure.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('molecules_per_cluster_unlabeled')))\n",
    "    display(Image(filename=figs_out('molecules_per_cluster_unlabeled_zoom')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('molecules_per_cluster_labeled')) or not os.path.exists(figs_out('molecules_per_cluster_labeled_zoom')) or reprocess:\n",
    "    g = sns.FacetGrid(\n",
    "        data=df_clusters_long.loc[df_clusters_long['label'].isin(labeled_targets)],\n",
    "        hue='variable',\n",
    "        col='label',\n",
    "        height=2.5,\n",
    "        col_wrap=4,\n",
    "        col_order=labeled_targets,\n",
    "        sharex=False\n",
    "    )\n",
    "    g.figure.set_constrained_layout(True)\n",
    "    g.figure.suptitle('Distribution of molecule counts per labeled cluster', y=1)\n",
    "    g.map(sns.ecdfplot, 'count')\n",
    "    g.add_legend()\n",
    "    g.savefig(figs_out('molecules_per_cluster_labeled'))\n",
    "    display(g.figure)\n",
    "\n",
    "    zoom_count_max = 15\n",
    "    [ax.set(xlim=(-0.5, zoom_count_max + 0.5)) for ax in g.axes.flatten()]\n",
    "    g.figure.suptitle('Distribution of molecule counts per labeled cluster (zoom)', y=1)\n",
    "    g.savefig(figs_out('molecules_per_cluster_labeled_zoom'))\n",
    "    g.figure.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('molecules_per_cluster_labeled')))\n",
    "    display(Image(filename=figs_out('molecules_per_cluster_labeled_zoom')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2428c8e8",
   "metadata": {},
   "source": [
    "Oligos per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45033056-31ac-4f6a-a536-1213e1250c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('oligos_per_cluster')) or reprocess:\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 5), constrained_layout=True, sharex='row', sharey='col')\n",
    "    fig.suptitle('Distribution of oligos per cluster')\n",
    "\n",
    "    axs[0, 0].hist(df_clusters['oligo count'], bins=50, log=True, align='left')\n",
    "    axs[0, 0].set(xlabel='Oligos per cluster', ylabel='Number of clusters', title='Histogram')\n",
    "    sns.ecdfplot(data=df_clusters, x='oligo count', ax=axs[0, 1])\n",
    "    axs[0, 1].set(xlabel='Oligos per cluster', ylabel='Proportion of clusters', title='eCDF')\n",
    "\n",
    "    # zoom\n",
    "    zoom_oligo_max = 70\n",
    "    mask_oligo_counts_zoom = df_clusters['oligo count'] <= zoom_oligo_max\n",
    "    bins = np.arange(zoom_oligo_max + 2) - 0.5\n",
    "    axs[1, 0].hist(df_clusters.loc[mask_oligo_counts_zoom, 'oligo count'], bins=bins, log=True, align='mid')\n",
    "    axs[1, 0].set(xticks=np.arange(0, zoom_oligo_max + 2, 3), xlabel='Oligos per cluster', ylabel='Number of clusters', title='Histogram (zoom)')\n",
    "    sns.ecdfplot(data=df_clusters, x='oligo count', ax=axs[1, 1])\n",
    "    axs[1, 1].set(xlim=(-0.5, zoom_oligo_max + 0.5), xlabel='Oligos per cluster', ylabel='Proportion of clusters', title='eCDF (zoom)')\n",
    "    fig.savefig(figs_out('oligos_per_cluster'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('oligos_per_cluster')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f651b02-f181-4472-97d6-eb97b4f58773",
   "metadata": {},
   "source": [
    "Mode oligo proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4584c-c892-41b3-bbb0-2ea56057e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('mode_oligo_proportion')) or reprocess:\n",
    "    fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(10, 8), constrained_layout=True, sharex=True, sharey='col')\n",
    "    fig.suptitle('Distribution of mode oligo proportion')\n",
    "\n",
    "    axs[0, 0].hist(df_clusters['mode oligo proportion'], log=True, bins=50)\n",
    "    axs[0, 0].set(ylabel='Number of clusters')\n",
    "    sns.ecdfplot(df_clusters['mode oligo proportion'], ax=axs[0, 1])\n",
    "    axs[0, 1].set(ylabel='Proportion of clusters')\n",
    "\n",
    "    axs[1, 0].hist(df_clusters_with_oligo['mode oligo proportion'], log=True, bins=50)\n",
    "    axs[1, 0].set(\n",
    "        ylabel='Number of clusters',\n",
    "        title='Filtered for > 0 oligos per cluster')\n",
    "    sns.ecdfplot(df_clusters_with_oligo['mode oligo proportion'], ax=axs[1, 1])\n",
    "    axs[1, 1].set(\n",
    "        ylabel='Proportion of clusters',\n",
    "        title='Filtered for > 0 oligos per cluster')\n",
    "\n",
    "    mask_oligos_gt1 = df_clusters_with_oligo['oligo count'] > 1\n",
    "    axs[2, 0].hist(df_clusters_with_oligo.loc[mask_oligos_gt1, 'mode oligo proportion'], log=True, bins=50)\n",
    "    axs[2, 0].set(\n",
    "        xlabel='Mode oligo proportion',\n",
    "        ylabel='Number of clusters',\n",
    "        title='Filtered for > 1 oligo per cluster')\n",
    "    sns.ecdfplot(df_clusters_with_oligo.loc[mask_oligos_gt1, 'mode oligo proportion'], ax=axs[2, 1])\n",
    "    axs[2, 1].set(\n",
    "        xlabel='Mode oligo proportion',\n",
    "        ylabel='Proportion of clusters',\n",
    "        title='Filtered for > 1 oligo per cluster')\n",
    "    fig.savefig(figs_out('mode_oligo_proportion'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('mode_oligo_proportion')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2bdde-2e12-4d62-80a9-fcbc44cc51f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "('Proportion of clusters with mixed oligos: '\n",
    " f\"{(df_clusters_with_oligo['mode oligo proportion'] < 1).sum() / n_clusters:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c9518-c5aa-48f4-951f-6a310f187ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "('Proportion of clusters with oligo mixing > 20%: '\n",
    " f\"{(df_clusters_with_oligo['mode oligo proportion'] < 0.8).sum() / n_clusters:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcc60f8-b38a-4830-a55a-081f7fd7a844",
   "metadata": {},
   "source": [
    "Chromatin per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec15382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters['chromatin count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10214cc-4039-48e0-a1bd-09ff5dedf1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('chromatin_per_cluster')) or reprocess:\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 5), constrained_layout=True, sharex='row', sharey='col')\n",
    "    fig.suptitle('Distribution of chromatin per cluster')\n",
    "\n",
    "    axs[0, 0].hist(df_clusters['chromatin count'], bins=50, log=True, align='left')\n",
    "    axs[0, 0].set(xlabel='Chromatin per cluster', ylabel='Number of clusters', title='Histogram')\n",
    "    sns.ecdfplot(data=df_clusters, x='chromatin count', ax=axs[0, 1])\n",
    "    axs[0, 1].set(xlabel='Chromatin per cluster', ylabel='Proportion of clusters', title='eCDF')\n",
    "    axs[0, 0].axvline(x=max_chromatin_cluster_size, c='C1', label='chromatin filter threshold')\n",
    "    axs[0, 1].axvline(x=max_chromatin_cluster_size, c='C1', label='chromatin filter threshold')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # zoom\n",
    "    zoom_chromatin_max = 15\n",
    "    mask_chromatin_counts_zoom = df_clusters['chromatin count'] <= zoom_chromatin_max\n",
    "    bins = np.arange(zoom_chromatin_max + 2) - 0.5\n",
    "    axs[1, 0].hist(df_clusters.loc[mask_chromatin_counts_zoom, 'chromatin count'], bins=bins, log=True, align='mid')\n",
    "    axs[1, 0].set(\n",
    "        xticks=np.arange(zoom_chromatin_max + 2),\n",
    "        xlabel='Chromatin per cluster',\n",
    "        ylabel='Number of clusters',\n",
    "        title='Histogram (zoom)')\n",
    "    sns.ecdfplot(data=df_clusters, x='chromatin count', ax=axs[1, 1])\n",
    "    axs[1, 1].set(\n",
    "        xlim=(-0.5, zoom_chromatin_max + 0.5),\n",
    "        xlabel='Chromatin per cluster',\n",
    "        ylabel='Proportion of clusters',\n",
    "        title='eCDF (zoom)')\n",
    "\n",
    "    fig.savefig(figs_out('chromatin_per_cluster'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('chromatin_per_cluster')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2078a77b",
   "metadata": {},
   "source": [
    "## Chromatin distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7681ad",
   "metadata": {},
   "source": [
    "Chromatin vs. chromatin per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d748c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('chromatin_v_chromatin_per_cluster')) or reprocess:\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 5), constrained_layout=True, sharex='row', sharey='col')\n",
    "    fig.suptitle('Distribution of chromatin per cluster')\n",
    "\n",
    "    axs[0, 0].hist(df_clusters['chromatin count'], weights=df_clusters['chromatin count'], bins=50, log=True, align='left')\n",
    "    axs[0, 0].set(xlabel='Chromatin per cluster', ylabel='Number of chromatin', title='Histogram')\n",
    "    sns.ecdfplot(data=df_clusters, x='chromatin count', weights='chromatin count', ax=axs[0, 1])\n",
    "    axs[0, 1].set(xlabel='Chromatin per cluster', ylabel='Proportion of chromatin', title='eCDF')\n",
    "    axs[0, 0].axvline(x=max_chromatin_cluster_size, c='C1', label='chromatin filter threshold')\n",
    "    axs[0, 1].axvline(x=max_chromatin_cluster_size, c='C1', label='chromatin filter threshold')\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # zoom\n",
    "    zoom_chromatin_max = 15\n",
    "    mask_chromatin_counts_zoom = df_clusters['chromatin count'] <= zoom_chromatin_max\n",
    "    bins = np.arange(zoom_chromatin_max + 2) - 0.5\n",
    "    axs[1, 0].hist(df_clusters.loc[mask_chromatin_counts_zoom, 'chromatin count'],\n",
    "                weights=df_clusters.loc[mask_chromatin_counts_zoom, 'chromatin count'],\n",
    "                bins=bins, log=True, align='mid')\n",
    "    axs[1, 0].set(\n",
    "        xticks=np.arange(zoom_chromatin_max + 2),\n",
    "        xlabel='Chromatin per cluster',\n",
    "        ylabel='Number of chromatin',\n",
    "        title='Histogram (zoom)')\n",
    "    sns.ecdfplot(data=df_clusters, x='chromatin count', weights='chromatin count', ax=axs[1, 1])\n",
    "    axs[1, 1].set(\n",
    "        xlim=(-0.5, zoom_chromatin_max + 0.5),\n",
    "        xlabel='Chromatin per cluster',\n",
    "        ylabel='Proportion of chromatin',\n",
    "        title='eCDF (zoom)')\n",
    "\n",
    "    fig.savefig(figs_out('chromatin_v_chromatin_per_cluster'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('chromatin_v_chromatin_per_cluster')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fbf414",
   "metadata": {},
   "source": [
    "Chromatin vs. oligos per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea940cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('chromatin_per_oligo_per_cluster')) or reprocess:\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 5), constrained_layout=True, sharex='row', sharey='col')\n",
    "    fig.suptitle('Distribution of chromatin per oligo per cluster')\n",
    "\n",
    "    sns.histplot(df_clusters, x='oligo count', weights='chromatin count', bins=50, log=True, ax=axs[0, 0])\n",
    "    axs[0, 0].set(xlabel='Oligos per cluster', ylabel='Number of chromatin', title='Histogram')\n",
    "    sns.ecdfplot(df_clusters, x='oligo count', weights='chromatin count', ax=axs[0, 1])\n",
    "    axs[0, 1].set(xlabel='Oligos per cluster', ylabel='Proportion of chromatin', title='eCDF')\n",
    "\n",
    "    # zoom\n",
    "    zoom_oligo_max = 15\n",
    "    mask_oligo_counts_zoom = df_clusters['oligo count'] <= zoom_oligo_max\n",
    "    sns.histplot(\n",
    "        df_clusters.loc[mask_oligo_counts_zoom],\n",
    "        x='oligo count',\n",
    "        weights='chromatin count',\n",
    "        bins=zoom_oligo_max + 1,\n",
    "        ax=axs[1, 0])\n",
    "    axs[1, 0].set(xlabel='Oligos per cluster', ylabel='Number of chromatin', title='Histogram (zoom)')\n",
    "    sns.ecdfplot(df_clusters, x='oligo count', weights='chromatin count', ax=axs[1, 1])\n",
    "    axs[1, 1].set(\n",
    "        xlabel='Oligos per cluster',\n",
    "        ylabel='Proportion of chromatin',\n",
    "        title='eCDF (zoom)',\n",
    "        xlim=(0, zoom_oligo_max))\n",
    "\n",
    "    fig.savefig(figs_out('chromatin_per_oligo_per_cluster'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('chromatin_per_oligo_per_cluster')))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d3f9894",
   "metadata": {},
   "source": [
    "# # Alternative without using seaborn - much faster\n",
    "# if not os.path.exists(figs_out('chromatin_per_oligo_per_cluster')):\n",
    "#     chromatin_per_oligos_per_cluster = df_clusters.groupby('oligo count')['chromatin count'].sum()\n",
    "\n",
    "#     bins = chromatin_per_oligos_per_cluster.index.values\n",
    "#     bins = np.append(bins, bins.max() + 1)\n",
    "\n",
    "#     bins_hist = pd.cut(chromatin_per_oligos_per_cluster.index, 50)\n",
    "#     chromatin_per_oligos_per_cluster.reset_index().groupby(bins_hist)['chromatin count'].sum()\n",
    "\n",
    "#     fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 5), constrained_layout=True, sharex='row', sharey='col')\n",
    "#     fig.suptitle('Distribution of chromatin per oligo per cluster')\n",
    "\n",
    "#     axs[0, 0].bar(\n",
    "#         [bin.mid for bin in bins_hist],\n",
    "#         chromatin_per_oligos_per_cluster.values,\n",
    "#         width=bins_hist[0].length,\n",
    "#         log=True)\n",
    "#     axs[0, 0].set(\n",
    "#         xlabel='Oligos per cluster',\n",
    "#         ylabel='Number of chromatin',\n",
    "#         title='Histogram',\n",
    "#         xlim=(-5, chromatin_per_oligos_per_cluster.index.values.max()))\n",
    "#     axs[0, 1].stairs(\n",
    "#         (chromatin_per_oligos_per_cluster / chromatin_per_oligos_per_cluster.sum()).cumsum(),\n",
    "#         bins)\n",
    "#     axs[0, 1].set(xlabel='Oligos per cluster', ylabel='Proportion of chromatin', title='eCDF', ylim=(0, 1))\n",
    "\n",
    "#     # zoom\n",
    "#     zoom_oligo_max = 15\n",
    "#     axs[1, 0].bar(\n",
    "#         chromatin_per_oligos_per_cluster.index.values[:zoom_oligo_max],\n",
    "#         chromatin_per_oligos_per_cluster.values[:zoom_oligo_max],\n",
    "#         width=1)\n",
    "#     axs[1, 0].set(\n",
    "#         xlabel='Oligos per cluster',\n",
    "#         ylabel='Number of chromatin',\n",
    "#         title='Histogram (zoom)',\n",
    "#         xlim=(-0.5, zoom_oligo_max - 0.5))\n",
    "#     axs[1, 1].stairs(\n",
    "#         (chromatin_per_oligos_per_cluster / chromatin_per_oligos_per_cluster.sum()).cumsum().iloc[:zoom_oligo_max],\n",
    "#         bins[:zoom_oligo_max + 1])\n",
    "#     axs[1, 1].set(\n",
    "#         xlabel='Oligos per cluster',\n",
    "#         ylabel='Proportion of chromatin',\n",
    "#         title='eCDF (zoom)',\n",
    "#         ylim=(0, 1))\n",
    "\n",
    "#     # fig.savefig(figs_out('chromatin_per_oligo_per_cluster'), bbox_inches='tight')\n",
    "#     fig.show()\n",
    "# else:\n",
    "#     display(Image(filename=figs_out('chromatin_per_oligo_per_cluster')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409b9118",
   "metadata": {},
   "source": [
    "Chromatin vs. mode oligo proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa04f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('chromatin_v_mode_oligo_proportion')) or reprocess:\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 3), constrained_layout=True, sharex=True)\n",
    "    fig.suptitle('Distribution of chromatin per mode oligo proportion')\n",
    "\n",
    "    axs[0].hist(df_clusters['mode oligo proportion'], weights=df_clusters['chromatin count'], bins=50, log=True)\n",
    "    # much slower: sns.histplot(df_clusters, x='mode oligo proportion', weights='chromatin count', bins=50, log=True)\n",
    "    axs[0].set(xlabel='Mode oligo proportion', ylabel='Number of chromatin', xlim=(0, 1))\n",
    "\n",
    "    chromatin_per_mode_oligo_proportion = df_clusters_with_oligo.groupby('mode oligo proportion')['chromatin count'].sum()\n",
    "    bins = chromatin_per_mode_oligo_proportion.index.values\n",
    "    bins = np.append(bins, bins.max() + 0.01)\n",
    "    axs[1].stairs(\n",
    "        (chromatin_per_mode_oligo_proportion / chromatin_per_mode_oligo_proportion.sum()).cumsum(),\n",
    "        bins)\n",
    "    # much slower: sns.ecdfplot(df_clusters, x='mode oligo proportion', weights='chromatin count', ax=axs[1])\n",
    "    axs[1].set(xlabel='Mode oligo proportion', ylabel='Proportion of chromatin', title='eCDF', ylim=(0, 1))\n",
    "\n",
    "    fig.savefig(figs_out('chromatin_v_mode_oligo_proportion'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('chromatin_v_mode_oligo_proportion')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c262aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "('Chromatin in clusters with mixed oligos: '\n",
    " f\"{df_clusters_with_oligo.loc[df_clusters_with_oligo['mode oligo proportion'] < 1, 'chromatin count'].sum()} \"\n",
    " f\"({df_clusters_with_oligo.loc[df_clusters_with_oligo['mode oligo proportion'] < 1, 'chromatin count'].sum() / count_chromatin_in_clusters:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc16de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(f'Chromatin in clusters with mode oligo propotion < {proportion} and 1+ oligo: '\n",
    " f\"{df_clusters_with_oligo.loc[df_clusters_with_oligo['mode oligo proportion'] < proportion, 'chromatin count'].sum()} \"\n",
    " f\"({df_clusters_with_oligo.loc[df_clusters_with_oligo['mode oligo proportion'] < proportion, 'chromatin count'].sum() / count_chromatin_in_clusters:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c18cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(f'Chromatin in clusters with mode oligo propotion < {proportion}, including clusters without oligos: '\n",
    " f\"{df_clusters.loc[df_clusters['mode oligo proportion'] < 0.8, 'chromatin count'].sum()} \"\n",
    " f\"({df_clusters.loc[df_clusters['mode oligo proportion'] < 0.8, 'chromatin count'].sum() / count_chromatin_in_clusters:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40dfa7b-3b2d-41d8-9ddf-657868c4e316",
   "metadata": {},
   "source": [
    "## Joint distributions of oligo and chromatin per cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a1ad0e",
   "metadata": {},
   "source": [
    "Heatmap of oligos per cluster vs. mode oligo proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('oligo_count_v_mode_oligo_proportion')) or reprocess:\n",
    "    max_oligo_counts_thresh = 15\n",
    "    cols = ['mode oligo proportion', 'oligo count']\n",
    "    mask_oligo_counts_lte_thresh = df_clusters_with_oligo['oligo count'] <= max_oligo_counts_thresh\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12, 3), constrained_layout=True, sharex=True, sharey=True)\n",
    "    sns.histplot(\n",
    "        data=df_clusters_with_oligo.loc[mask_oligo_counts_lte_thresh, cols],\n",
    "        x=cols[0], y=cols[1],\n",
    "        binwidth=(0.1, 1),\n",
    "        cbar=True, cbar_kws=dict(label='number of clusters'),\n",
    "        ax=axs[0])\n",
    "    axs[0].set(title='Distribution of clusters')\n",
    "\n",
    "    mask_oligos_gt1 = df_clusters_with_oligo['oligo count'] > 1\n",
    "    sns.histplot(\n",
    "        data=df_clusters_with_oligo.loc[mask_oligo_counts_lte_thresh & mask_oligos_gt1, cols],\n",
    "        x=cols[0], y=cols[1],\n",
    "        binwidth=(0.1, 1),\n",
    "        cbar=True, cbar_kws=dict(label='number of clusters'),\n",
    "        ax=axs[1])\n",
    "    axs[1].set(title='Distribution of clusters with > 1 oligo')\n",
    "\n",
    "    sns.histplot(\n",
    "        data=df_clusters_with_oligo.loc[mask_oligo_counts_lte_thresh, cols + ['chromatin count']],\n",
    "        x=cols[0], y=cols[1], weights='chromatin count',\n",
    "        binwidth=(0.1, 1),\n",
    "        cbar=True, cbar_kws=dict(label='chromatin count'),\n",
    "        ax=axs[2])\n",
    "    axs[2].set(\n",
    "        xlim=(0, 1),\n",
    "        ylim=(1, max_oligo_counts_thresh),\n",
    "        title='Distribution of chromatin')\n",
    "    fig.savefig(figs_out('oligo_count_v_mode_oligo_proportion'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('oligo_count_v_mode_oligo_proportion')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3a9bd8-9248-4a5b-87cd-d28390d62cb7",
   "metadata": {},
   "source": [
    "## Analysis of unlabeled clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbabecd",
   "metadata": {},
   "source": [
    "### Uncertain clusters\n",
    "\n",
    "Mode oligo count = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89da829b",
   "metadata": {},
   "source": [
    "What is the distribution of oligos (labels)?\n",
    "- In how many uncertain clusters is each oligo found in?\n",
    "- How much chromatin is contained in those clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(csv_out('uncertain_counts_per_target')) or reprocess:\n",
    "    uncertain_target_template = {\n",
    "        'unique cluster': 0,\n",
    "        'unique chromatin': 0,\n",
    "        'mixed cluster': 0,\n",
    "        'mixed chromatin': 0\n",
    "    }\n",
    "    uncertain_target_distribution = {target: uncertain_target_template.copy() for target in labeled_targets}\n",
    "    for barcode, row in tqdm(df_clusters.loc[df_clusters['label'] == 'uncertain'].iterrows(), total=df_counts_per_target.loc['uncertain', 'cluster count'].item()):\n",
    "        cluster_type = 'mixed' if row['oligo count'] > 1 else 'unique'\n",
    "        for target in label_distribution[barcode]:\n",
    "            uncertain_target_distribution[target][f'{cluster_type} cluster'] += 1\n",
    "            uncertain_target_distribution[target][f'{cluster_type} chromatin'] += row['chromatin count']\n",
    "    df_uncertain = pd.DataFrame.from_dict(uncertain_target_distribution, orient='index')\n",
    "    df_uncertain.to_csv(csv_out('uncertain_counts_per_target'))\n",
    "else:\n",
    "    df_uncertain = pd.read_csv(csv_out('uncertain_counts_per_target'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e5b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('uncertain_target_distribution')) or reprocess:\n",
    "    with sns.axes_style('darkgrid'):\n",
    "        g = sns.catplot(\n",
    "            data=df_uncertain \\\n",
    "                .reset_index(names='label') \\\n",
    "                .melt(id_vars='label', value_name='count') \\\n",
    "                .pipe(lambda df: pd.concat(\n",
    "                    (df[['label', 'count']],\n",
    "                    df['variable'].str.extract('(?P<cluster_type>unique|mixed) (?P<unit>cluster|chromatin)')),\n",
    "                    axis=1)) \\\n",
    "                .pipe(lambda df: df.assign(cluster_type=df['cluster_type'].map({'unique': 'unique oligo', 'mixed': 'mixed oligos'}))) \\\n",
    "                .sort_values('label', key=lambda series: series.map(label_order)),\n",
    "            kind='bar',\n",
    "            x='count',\n",
    "            y='label',\n",
    "            hue='cluster_type',\n",
    "            col='unit',\n",
    "            col_order=('cluster', 'chromatin'),\n",
    "            sharex=False\n",
    "        )\n",
    "        [ax.yaxis.grid(True) for ax in g.axes.flatten()]\n",
    "        g.figure.suptitle('Distribution of oligos in uncertain clusters', y=1)\n",
    "        g.figure.set_size_inches(8, 7)\n",
    "        sns.move_legend(g, 'right', bbox_to_anchor=(1.05, 0.5))\n",
    "        g.savefig(figs_out('uncertain_target_distribution'))\n",
    "else:\n",
    "    display(Image(filename=figs_out('uncertain_target_distribution')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a39fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('uncertain_label_representation')) or reprocess:\n",
    "    with sns.axes_style('darkgrid'):\n",
    "        df_uncertain_compare = pd.concat(\n",
    "            (df_uncertain[['unique cluster', 'unique chromatin']],\n",
    "            df_counts_per_target[['cluster count', 'chromatin count']]),\n",
    "            axis=1) \\\n",
    "            .dropna(axis=0) \\\n",
    "            .apply(lambda s: s/s.sum(), axis=0)\n",
    "        df_uncertain_compare['cluster proportion diff'] = df_uncertain_compare['unique cluster'] - df_uncertain_compare['cluster count']\n",
    "        df_uncertain_compare['chromatin proportion diff'] = df_uncertain_compare['unique chromatin'] - df_uncertain_compare['chromatin count']\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 7), constrained_layout=True)\n",
    "        fig.suptitle('Over/underrepresentation of labels among uncertain clusters')\n",
    "        sns.barplot(\n",
    "            data=df_uncertain_compare[['cluster proportion diff', 'chromatin proportion diff']] \\\n",
    "                .rename(columns={'cluster proportion diff': 'cluster', 'chromatin proportion diff': 'chromatin'})\n",
    "                .reset_index(names='label') \\\n",
    "                .melt(id_vars='label', var_name='unit', value_name='proportion difference') \\\n",
    "                .sort_values('label', key=lambda series: series.map(label_order)),\n",
    "            x='proportion difference',\n",
    "            y='label',\n",
    "            hue='unit',\n",
    "            ax=ax\n",
    "        )\n",
    "        fig.text(\n",
    "            0.1,\n",
    "            -0.05,\n",
    "            ('Proportion difference =\\n'\n",
    "             '    fraction of uncertain clusters/chromatin with a given label\\n'\n",
    "             '    - fraction of properly labeled clusters/chromatin with a given label'),\n",
    "             horizontalalignment='left')\n",
    "        g.savefig(figs_out('uncertain_label_representation'))\n",
    "else:\n",
    "    display(Image(filename=figs_out('uncertain_label_representation')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbad0c7",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "- Most targets comprise a similar fraction of chromatin/clusters that are labeled by a single oligo as by multiple oligos.\n",
    "- A larger-than-expected fraction of chromatin in clusters with a single oligo are labeled by (targets with positive proportion difference values) compared to chromatin in properly labeled clusters.\n",
    "- A smaller-than-expected fraction of chromatin in clusters with a single oligo are labeled by (targets with negative proportion difference values) compared to chromatin in properly labeled clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e0ac0",
   "metadata": {},
   "source": [
    "### Ambiguous clusters\n",
    "\n",
    "- Mode oligo count >= 2 reads\n",
    "- Mode oligo proportion < 0.8\n",
    "- Chromatin count <= 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b960bae",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "- Oligo hopping --> normal oligo count\n",
    "  - Check if chromatin count matches distribution of most common oligo \n",
    "- Multiple protein G-antibody beads stuck together throughout split-pool barcoding --> large oligo count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('ambiguous_cluster_oligo_counts')) or reprocess:\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(8, 3), constrained_layout=True, sharex=True)\n",
    "    fig.suptitle('Distribution of oligo count among clusters')\n",
    "    axs[0].hist(\n",
    "        df_clusters.loc[df_clusters['label'].isin(labeled_targets), 'oligo count'].pipe(lambda s: s.loc[(s < 20) & (s > 2)]),\n",
    "        bins=np.arange(3, 21),\n",
    "        log=True,\n",
    "        align='left'\n",
    "    )\n",
    "    axs[0].set(xlabel='oligos per cluster', ylabel='number of clusters', title='Labeled clusters')\n",
    "    axs[1].hist(\n",
    "        df_clusters.loc[df_clusters['label'] == 'ambiguous', 'oligo count'].pipe(lambda s: s.loc[s < 20]),\n",
    "        bins=np.arange(3, 21),\n",
    "        log=True,\n",
    "        align='left')\n",
    "    axs[1].set(\n",
    "        xticks=np.arange(3, 21, 3),\n",
    "        xlabel='oligos per cluster',\n",
    "        ylabel='number of clusters',\n",
    "        title='Ambiguous clusters'\n",
    "    )\n",
    "    fig.savefig(figs_out('ambiguous_cluster_oligo_counts'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('ambiguous_cluster_oligo_counts')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38c1283",
   "metadata": {},
   "source": [
    "There may be a large drop in the number of ambiguous clusters from 4 to 5 oligos per cluster (and similar but smaller drops from 9 to 10 and from 14 to 15 oligos per cluster), which we do not observe among properly labeled clusters. This is perhaps not unexpected, since the threshold for labeling a cluster is a proportion of 0.8 - which allows for 1 \"wrong\" oligo out of 5. This analysis suggests that the `proportion=0.8` threshold of labeling clusters is very conserative: most of the clusters with 4 oligos likely contain 1 \"wrong\" oligo and 3 \"correct\" oligos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ceb1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters.loc[(df_clusters['oligo count'] == 4) & (df_clusters['label'] == 'ambiguous')].index \\\n",
    "    .to_series() \\\n",
    "    .map(lambda barcode: tuple(sorted(label_distribution[barcode].values()))) \\\n",
    "    .value_counts() \\\n",
    "    .rename('cluster count') \\\n",
    "    .to_frame() \\\n",
    "    .pipe(lambda df: df.assign(proportion=df['cluster count'] / df['cluster count'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ccf4e9",
   "metadata": {},
   "source": [
    "Check the amount of chromatin in clusters with 3 presumably \"correct\" oligos and 1 \"wrong\" oligo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01ba52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clusters.loc[(df_clusters['oligo count'] == 4) & (df_clusters['label'] == 'ambiguous')] \\\n",
    "    .pipe(lambda df: df.loc[df.index.to_series().map(lambda barcode: tuple(sorted(label_distribution[barcode].values())) == (1, 3))]) \\\n",
    "    ['chromatin count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9c4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('ambiguous_clusters_heatmap')) or reprocess:\n",
    "    fig, ax = plt.subplots(constrained_layout=True)\n",
    "    fig.suptitle('Distribution of ambiguous clusters by chromatin count and oligo count')\n",
    "    sns.histplot(\n",
    "        data=df_clusters.loc[df_clusters['label'] == 'ambiguous', ['oligo count', 'chromatin count']].map(lambda x: np.maximum(x, 0.1)),\n",
    "        x='oligo count',\n",
    "        y='chromatin count',\n",
    "        bins=25,\n",
    "        cbar=True,\n",
    "        cbar_kws=dict(label='Number of clusters'),\n",
    "        log_scale=(True, True),\n",
    "        norm=matplotlib.colors.LogNorm(),\n",
    "        vmin=None, vmax=None,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_yticks(\n",
    "        ticks=[1e-1, 1e0, 1e1, 1e2, 1e3, 1e4],\n",
    "        labels=['$0$', '$1$', '$\\\\mathdefault{10^{1}}$', '$\\\\mathdefault{10^{2}}$', '$\\\\mathdefault{10^{3}}$', '$\\\\mathdefault{10^{4}}$']\n",
    "    )\n",
    "    fig.savefig(figs_out('ambiguous_clusters_heatmap'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('ambiguous_clusters_heatmap')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ed2c38-8d5b-45fd-bb5b-7e56275a6cbd",
   "metadata": {},
   "source": [
    "### Filtered clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a1a474",
   "metadata": {},
   "source": [
    "Interpretation\n",
    "- A chromatin-dense cluster with high oligo count (relative to properly labeled clusters) presumably reflects multiple protein G-antibody beads stuck together throughout split-pool barcoding. This could potentially indicate colocalization of target proteins on a region of chromatin.\n",
    "- A chromatin-dense cluster with low oligo count presumably reflects an aggregate of crosslinked chromatin immunoprecipitated onto an individual bead. This could potentially indicate chromatin-chromatin interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86012518",
   "metadata": {},
   "source": [
    "Check oligo distribution of filtered clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7828c82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('filtered_cluster_oligo_counts')) or reprocess:\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(8, 3), constrained_layout=True, sharex=True)\n",
    "    fig.suptitle('Distribution of oligo count among clusters')\n",
    "    axs[0].hist(\n",
    "        df_clusters.loc[df_clusters['label'].isin(labeled_targets), 'oligo count'], #.pipe(lambda s: s.loc[(s < 20) & (s > 2)]),\n",
    "        bins=50,\n",
    "        range=(1, 1000),\n",
    "        log=True\n",
    "    )\n",
    "    axs[0].set(xlabel='oligos per cluster', ylabel='number of clusters', title='Labeled clusters')\n",
    "    axs[1].hist(\n",
    "        df_clusters.loc[df_clusters['label'] == 'filtered', 'oligo count'], #.pipe(lambda s: s.loc[s < 20]),\n",
    "        bins=50,\n",
    "        range=(1, 1000),\n",
    "        log=True\n",
    "    )\n",
    "    axs[1].set(\n",
    "        xlabel='oligos per cluster',\n",
    "        ylabel='number of clusters',\n",
    "        title='Filtered clusters'\n",
    "    )\n",
    "    fig.text(0.1, -0.05, 'Note: There are a few clusters with >1000 oligos not shown in this figure.')\n",
    "    fig.savefig(figs_out('filtered_cluster_oligo_counts'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('filtered_cluster_oligo_counts')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec1dac",
   "metadata": {},
   "source": [
    "# Colocalization Analysis\n",
    "\n",
    "Idea: Clusters with multiple oligos may represent colocalization of targets on chromatin.\n",
    "\n",
    "Criteria for including a target in a cluster\n",
    "- Count of target oligo >= 2\n",
    "- Proportion of target oligo >= 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa91c2",
   "metadata": {},
   "source": [
    "Colocalization heatmaps\n",
    "- Restrict to clusters with chromatin\n",
    "- Apply criteria for including targets in a clusters\n",
    "- Normalization strategy 1\n",
    "  - Interaction frequency matrix $M$ construction: for each cluster containing both target $i$ and target $j \\neq 1$, increment $M_{i,j}$ and $M_{j,i}$ each by 1.\n",
    "    - Include self-interactions: increment $M_{i,i}$ by 1\n",
    "  - Matrix normalization: divide each row by the number of clusters that the row-target is in (i.e., the diagonal element value of that row)\n",
    "    - $\\tilde{M}_{i,j} = M_{i,j} / M_{i,i}$\n",
    "    - Normalized value interpretation: $\\tilde{M}_{i,j}$ is the proportion of chromatin-containing target $i$ clusters that also contain target $j$.\n",
    "- Normalization strategy 2\n",
    "  - Interaction frequency matrix $M$ construction: for each cluster containing both target $i$ and target $j$, increment $M_{i,j}$ and $M_{j,i}$ each by $2/n$, where $n$ is the number of targets in that cluster.\n",
    "  - Matrix normalization: divide each row by the number of pairwise interactions that the row-target is in (i.e., the row sum, excluding the diagonal element)\n",
    "    - Ignore self-interactions: $\\tilde{M}_{i,i} = 1$\n",
    "    - Normalized value interpretation: $\\tilde{M}_{i,j}$ is the proportion of target $i$'s *pairwise colocalizations* on chromatin involving target $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382249dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_by_clusters(df, pseudocount=None):\n",
    "    '''\n",
    "    Normalize a matrix of interactions by the number of clusters.\n",
    "    - NA values (i.e., targets not present in any cluster) are replaced with zeros.\n",
    "    - 0 values are optionally replaced with a pseudocount.\n",
    "\n",
    "    Args\n",
    "    - df: pd.DataFrame. shape=(n, n)\n",
    "        df.loc[i, j] gives the count of clusters containing both targets i and j.\n",
    "        df.loc[i, i] gives the number of clusters containing target i.\n",
    "    - pseudocount: numeric or str. default=None\n",
    "        If None, do not add a pseudocount.\n",
    "        If numeric, add this value to all entries in df.\n",
    "        If 'min_over_ten', replace 0s with the minimum positive value in df / 10.\n",
    "\n",
    "    Returns: pd.DataFrame. shape=(n, n)\n",
    "    '''\n",
    "    df_norm = df / np.diag(df)[:, None]\n",
    "    df_norm.fillna(0, inplace=True)\n",
    "    if isinstance(pseudocount, (int, float)):\n",
    "        df_norm += pseudocount\n",
    "    elif pseudocount == 'min_over_ten':\n",
    "        df_norm.replace(0, df_norm.values[df_norm.values > 0].min() / 10, inplace=True)\n",
    "    else:\n",
    "        assert pseudocount is None\n",
    "    return df_norm\n",
    "\n",
    "def normalize_by_pairwise(df, pseudocount=None):\n",
    "    '''\n",
    "    Normalize a matrix of pairwise interactions by the number of pairwise interactions.\n",
    "    - NA values (i.e., targets not present in any cluster) are replaced with zeros.\n",
    "    - 0 values are optionally replaced with a pseudocount.\n",
    "    - The diagonal of the returned matrix is set to 1.\n",
    "\n",
    "    Args\n",
    "    - df: pd.DataFrame. shape=(n, n)\n",
    "        df.loc[i, j] gives the count of pairwise containing both targets i and j.\n",
    "        df.loc[i, i] is ignored\n",
    "    - pseudocount: numeric or str. default=None\n",
    "        If None, do not add a pseudocount.\n",
    "        If numeric, add this value to all entries in df.\n",
    "        If 'min_over_ten', replace 0s with the minimum positive value in df / 10.\n",
    "\n",
    "    Returns: pd.DataFrame. shape=(n, n)\n",
    "    '''\n",
    "    df_norm = df.copy()\n",
    "    np.fill_diagonal(df_norm.values, 0)\n",
    "    df_norm = df_norm / df_norm.values.sum(axis=1, keepdims=True)\n",
    "    df_norm.fillna(0, inplace=True)\n",
    "    np.fill_diagonal(df_norm.values, 1)\n",
    "    if isinstance(pseudocount, (int, float)):\n",
    "        df_norm += pseudocount\n",
    "    elif pseudocount == 'min_over_ten':\n",
    "        df_norm.replace(0, df_norm.values[df_norm.values > 0].min() / 10, inplace=True)\n",
    "    else:\n",
    "        assert pseudocount is None\n",
    "    return df_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98a569b",
   "metadata": {},
   "source": [
    "## All clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1eb9c5",
   "metadata": {},
   "source": [
    "Hierarchical clustering of barcodes (clusters) by which targets they contain.\n",
    "- To reduce matrix size, restrict to clusters with putative real interactions meeting the following criteria:\n",
    "  - Contain chromatin\n",
    "  - Contain 2+ real targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65126ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figs_out('clustermap')) or reprocess:\n",
    "    df_interact = df_clusters.loc[\n",
    "        (df_clusters['chromatin count'] > 0) &\n",
    "        (df_clusters['oligo count'] > 1) &\n",
    "        (df_clusters['mode oligo count'] < df_clusters['oligo count'])]\n",
    "    df_interact = pd.DataFrame(\n",
    "        [label_distribution[barcode] for barcode in df_interact.index],\n",
    "        columns=labeled_targets\n",
    "    ).fillna(0).astype(int)\n",
    "    mask_multiple_real_targets = (\n",
    "        ((df_interact >= 2).sum(axis=1) >= 2) &\n",
    "        ((df_interact.div(df_interact.sum(axis=1), axis=0) >= 0.1).sum(axis=1) >= 2))\n",
    "    g = sns.clustermap(\n",
    "        df_interact.loc[mask_multiple_real_targets].pipe(lambda df: df.div(df.sum(axis=1), axis=0)).T,\n",
    "        xticklabels=False,\n",
    "        cbar_kws=dict(label='proportion of oligo\\nin cluster'))\n",
    "    g.savefig(figs_out('clustermap'))\n",
    "    g.figure.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('clustermap')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf9d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all(map(\n",
    "    os.path.exists,\n",
    "    (csv_out('interactions_all_pairwise'),\n",
    "     csv_out('interactions_all_clusters'),\n",
    "     figs_out('interactions_all')))) or reprocess:\n",
    "\n",
    "    mask_interacting_clusters = \\\n",
    "        (df_clusters['chromatin count'] > 0) & \\\n",
    "        (df_clusters['mode oligo count'] > 1) & \\\n",
    "        (df_clusters['mode oligo count'] >= df_clusters['oligo count'] * 0.1)\n",
    "\n",
    "    interactions_all_clusters = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        dtype_in=float,\n",
    "        n_processes=n_processes)\n",
    "    df_interactions_all_clusters = pd.DataFrame(interactions_all_clusters, index=labeled_targets, columns=labeled_targets)\n",
    "    # save as DataFrame to preserve index and column labels\n",
    "    df_interactions_all_clusters.to_csv(csv_out('interactions_all_clusters'))\n",
    "\n",
    "    interactions_all_pairwise = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        n_processes=n_processes,\n",
    "        downweighting='n_over_two',\n",
    "        dtype_in=float)\n",
    "    df_interactions_all_pairwise = pd.DataFrame(interactions_all_pairwise, index=labeled_targets, columns=labeled_targets)\n",
    "    df_interactions_all_pairwise.to_csv(csv_out('interactions_all_pairwise'))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, width_ratios=(1, 1), figsize=(10, 5), layout='constrained', gridspec_kw=dict(wspace=0.2))\n",
    "    fig.suptitle('Colocalization in all chromatin-containing clusters')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_clusters(df_interactions_all_clusters, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target clusters\\nthat also contain columns targets'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[0]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[0])\n",
    "    axs[0].set(title='Cluster count normalization')\n",
    "    axs[0].tick_params(labelsize='xx-small')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_pairwise(df_interactions_all_pairwise, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target colocalizations\\ninvolving columns target'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[1]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[1])\n",
    "    axs[1].set(title='Pairwise count normalization')\n",
    "    axs[1].tick_params(labelsize='xx-small')\n",
    "    fig.savefig(figs_out('interactions_all'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('interactions_all')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442371f5",
   "metadata": {},
   "source": [
    "## Ambiguous clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee01258",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all(map(\n",
    "    os.path.exists,\n",
    "    (csv_out('interactions_ambiguous_pairwise'),\n",
    "     csv_out('interactions_ambiguous_clusters'),\n",
    "     figs_out('interactions_ambiguous')))) or reprocess:\n",
    "\n",
    "    mask_interacting_clusters = \\\n",
    "        (df_clusters['label'] == 'ambiguous') & \\\n",
    "        (df_clusters['chromatin count'] > 0) & \\\n",
    "        (df_clusters['mode oligo count'] > 1) & \\\n",
    "        (df_clusters['mode oligo count'] >= df_clusters['oligo count'] * 0.1)\n",
    "\n",
    "    interactions_ambiguous_clusters = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        dtype_in=float,\n",
    "        n_processes=n_processes)\n",
    "    df_interactions_ambiguous_clusters = pd.DataFrame(interactions_ambiguous_clusters, index=labeled_targets, columns=labeled_targets)\n",
    "    # save as DataFrame to preserve index and column labels\n",
    "    df_interactions_ambiguous_clusters.to_csv(csv_out('interactions_ambiguous_clusters'))\n",
    "\n",
    "    interactions_ambiguous_pairwise = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        downweighting='n_over_two',\n",
    "        dtype_in=float,\n",
    "        n_processes=n_processes)\n",
    "    df_interactions_ambiguous_pairwise = pd.DataFrame(interactions_ambiguous_pairwise, index=labeled_targets, columns=labeled_targets)\n",
    "    df_interactions_ambiguous_pairwise.to_csv(csv_out('interactions_ambiguous_pairwise'))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, width_ratios=(1, 1), figsize=(10, 5), layout='constrained', gridspec_kw=dict(wspace=0.2))\n",
    "    fig.suptitle('Colocalization in ambiguous clusters')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_clusters(df_interactions_ambiguous_clusters, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target clusters\\nthat also contain columns targets'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[0]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[0])\n",
    "    axs[0].set(title='Cluster count normalization')\n",
    "    axs[0].tick_params(labelsize='xx-small')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_pairwise(df_interactions_ambiguous_pairwise, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target colocalizations\\ninvolving columns target'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[1]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[1])\n",
    "    axs[1].set(title='Pairwise count normalization')\n",
    "    axs[1].tick_params(labelsize='xx-small')\n",
    "    fig.savefig(figs_out('interactions_ambiguous'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('interactions_ambiguous')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4332494",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all(map(\n",
    "    os.path.exists,\n",
    "    (csv_out('interactions_ambiguous_large_pairwise'),\n",
    "     csv_out('interactions_ambiguous_large_clusters'),\n",
    "     figs_out('interactions_ambiguous_large')))) or reprocess:\n",
    "\n",
    "    mask_interacting_clusters = \\\n",
    "        (df_clusters['label'] == 'ambiguous') & \\\n",
    "        (df_clusters['chromatin count'] > 0) & \\\n",
    "        (df_clusters['mode oligo count'] > 1) & \\\n",
    "        (df_clusters['mode oligo count'] >= df_clusters['oligo count'] * 0.1)\n",
    "\n",
    "    interactions_ambiguous_large_clusters = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        dtype_in=float,\n",
    "        n_processes=n_processes)\n",
    "    df_interactions_ambiguous_large_clusters = pd.DataFrame(interactions_ambiguous_large_clusters, index=labeled_targets, columns=labeled_targets)\n",
    "    # save as DataFrame to preserve index and column labels\n",
    "    df_interactions_ambiguous_large_clusters.to_csv(csv_out('interactions_ambiguous_large_clusters'))\n",
    "\n",
    "    interactions_ambiguous_large_pairwise = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        downweighting='n_over_two',\n",
    "        dtype_in=float,\n",
    "        n_processes=n_processes)\n",
    "    df_interactions_ambiguous_large_pairwise = pd.DataFrame(interactions_ambiguous_large_pairwise, index=labeled_targets, columns=labeled_targets)\n",
    "    df_interactions_ambiguous_large_pairwise.to_csv(csv_out('interactions_ambiguous_large_pairwise'))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, width_ratios=(1, 1), figsize=(10, 5), layout='constrained', gridspec_kw=dict(wspace=0.2))\n",
    "    fig.suptitle('Colocalization in large ambiguous clusters')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_clusters(df_interactions_ambiguous_large_clusters, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target clusters\\nthat also contain columns targets'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[0]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[0])\n",
    "    axs[0].set(title='Cluster count normalization')\n",
    "    axs[0].tick_params(labelsize='xx-small')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_pairwise(df_interactions_ambiguous_large_pairwise, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target colocalizations\\ninvolving columns target'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[1]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[1])\n",
    "    axs[1].set(title='Pairwise count normalization')\n",
    "    axs[1].tick_params(labelsize='xx-small')\n",
    "    fig.savefig(figs_out('interactions_ambiguous_large'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('interactions_ambiguous_large')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b8389d",
   "metadata": {},
   "source": [
    "## Filtered clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d65d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all(map(\n",
    "    os.path.exists,\n",
    "    (csv_out('interactions_filtered_pairwise'),\n",
    "     csv_out('interactions_filtered_clusters'),\n",
    "     figs_out('interactions_filtered')))) or reprocess:\n",
    "\n",
    "    mask_interacting_clusters = \\\n",
    "        (df_clusters['label'] == 'filtered') & \\\n",
    "        (df_clusters['chromatin count'] > 0) & \\\n",
    "        (df_clusters['mode oligo count'] > 1) & \\\n",
    "        (df_clusters['mode oligo count'] >= df_clusters['oligo count'] * 0.1)\n",
    "\n",
    "    interactions_filtered_clusters = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        dtype_in=float,\n",
    "        n_processes=n_processes)\n",
    "    df_interactions_filtered_clusters = pd.DataFrame(interactions_filtered_clusters, index=labeled_targets, columns=labeled_targets)\n",
    "    # save as DataFrame to preserve index and column labels\n",
    "    df_interactions_filtered_clusters.to_csv(csv_out('interactions_filtered_clusters'))\n",
    "\n",
    "    interactions_filtered_pairwise = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        downweighting='n_over_two',\n",
    "        dtype_in=float,\n",
    "        n_processes=n_processes)\n",
    "    df_interactions_filtered_pairwise = pd.DataFrame(interactions_filtered_pairwise, index=labeled_targets, columns=labeled_targets)\n",
    "    df_interactions_filtered_pairwise.to_csv(csv_out('interactions_filtered_pairwise'))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, width_ratios=(1, 1), figsize=(10, 5), layout='constrained', gridspec_kw=dict(wspace=0.2))\n",
    "    fig.suptitle('Colocalization in filtered clusters')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_clusters(df_interactions_filtered_clusters, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target clusters\\nthat also contain columns targets'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[0]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[0])\n",
    "    axs[0].set(title='Cluster count normalization')\n",
    "    axs[0].tick_params(labelsize='xx-small')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_pairwise(df_interactions_filtered_pairwise, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target colocalizations\\ninvolving columns target'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[1]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[1])\n",
    "    axs[1].set(title='Pairwise count normalization')\n",
    "    axs[1].tick_params(labelsize='xx-small')\n",
    "    fig.savefig(figs_out('interactions_filtered'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('interactions_filtered')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2433cbd",
   "metadata": {},
   "source": [
    "Interaction analysis of filtered clusters with high oligo counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c1f620",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_oligo_count_thresh = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b851ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all(map(\n",
    "    os.path.exists,\n",
    "    (csv_out('interactions_filtered_high_oligo_pairwise'),\n",
    "     csv_out('interactions_filtered_high_oligo_clusters'),\n",
    "     figs_out('interactions_filtered_high_oligo')))) or reprocess:\n",
    "\n",
    "    mask_interacting_clusters = \\\n",
    "        (df_clusters['label'] == 'filtered') & \\\n",
    "        (df_clusters['chromatin count'] > 0) & \\\n",
    "        (df_clusters['oligo count'] >= high_oligo_count_thresh) & \\\n",
    "        (df_clusters['mode oligo count'] >= df_clusters['oligo count'] * 0.1)\n",
    "\n",
    "    interactions_filtered_high_oligo_clusters = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        dtype_in=float,\n",
    "        n_processes=n_processes)\n",
    "    df_interactions_filtered_high_oligo_clusters = pd.DataFrame(interactions_filtered_high_oligo_clusters, index=labeled_targets, columns=labeled_targets)\n",
    "    # save as DataFrame to preserve index and column labels\n",
    "    df_interactions_filtered_high_oligo_clusters.to_csv(csv_out('interactions_filtered_high_oligo_clusters'))\n",
    "\n",
    "    interactions_filtered_high_oligo_pairwise = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        downweighting='n_over_two',\n",
    "        dtype_in=float,\n",
    "        n_processes=n_processes)\n",
    "    df_interactions_filtered_high_oligo_pairwise = pd.DataFrame(interactions_filtered_high_oligo_pairwise, index=labeled_targets, columns=labeled_targets)\n",
    "    df_interactions_filtered_high_oligo_pairwise.to_csv(csv_out('interactions_filtered_high_oligo_pairwise'))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, width_ratios=(1, 1), figsize=(10, 5), layout='constrained', gridspec_kw=dict(wspace=0.2))\n",
    "    fig.suptitle('Colocalization in filtered_high_oligo clusters')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_clusters(df_interactions_filtered_high_oligo_clusters, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target clusters\\nthat also contain columns targets'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[0]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[0])\n",
    "    axs[0].set(title='Cluster count normalization')\n",
    "    axs[0].tick_params(labelsize='xx-small')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_pairwise(df_interactions_filtered_high_oligo_pairwise, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target colocalizations\\ninvolving columns target'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[1]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[1])\n",
    "    axs[1].set(title='Pairwise count normalization')\n",
    "    axs[1].tick_params(labelsize='xx-small')\n",
    "    fig.savefig(figs_out('interactions_filtered_high_oligo'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('interactions_filtered_high_oligo')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d4299",
   "metadata": {},
   "source": [
    "Interaction analysis of filtered clusters with low oligo counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1031b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_oligo_counts_thresh = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff176cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all(map(\n",
    "    os.path.exists,\n",
    "    (csv_out('interactions_filtered_low_oligo_pairwise'),\n",
    "     csv_out('interactions_filtered_low_oligo_clusters'),\n",
    "     figs_out('interactions_filtered_low_oligo')))) or reprocess:\n",
    "\n",
    "    mask_interacting_clusters = \\\n",
    "        (df_clusters['label'] == 'filtered') & \\\n",
    "        (df_clusters['chromatin count'] > 0) & \\\n",
    "        (df_clusters['oligo count'] <= low_oligo_counts_thresh) & \\\n",
    "        (df_clusters['mode oligo count'] >= df_clusters['oligo count'] * 0.1)\n",
    "\n",
    "    interactions_filtered_low_oligo_clusters = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        dtype_in=float,\n",
    "        n_processes=n_processes)\n",
    "    df_interactions_filtered_low_oligo_clusters = pd.DataFrame(interactions_filtered_low_oligo_clusters, index=labeled_targets, columns=labeled_targets)\n",
    "    # save as DataFrame to preserve index and column labels\n",
    "    df_interactions_filtered_low_oligo_clusters.to_csv(csv_out('interactions_filtered_low_oligo_clusters'))\n",
    "\n",
    "    interactions_filtered_low_oligo_pairwise = label_counts_to_interaction_chunked(\n",
    "        (label_distribution[barcode] for barcode in df_clusters.loc[mask_interacting_clusters].index),\n",
    "        labeled_targets,\n",
    "        downweighting='n_over_two',\n",
    "        dtype_in=float,\n",
    "        n_processes=n_processes)\n",
    "    df_interactions_filtered_low_oligo_pairwise = pd.DataFrame(interactions_filtered_low_oligo_pairwise, index=labeled_targets, columns=labeled_targets)\n",
    "    df_interactions_filtered_low_oligo_pairwise.to_csv(csv_out('interactions_filtered_low_oligo_pairwise'))\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, width_ratios=(1, 1), figsize=(10, 5), layout='constrained', gridspec_kw=dict(wspace=0.2))\n",
    "    fig.suptitle('Colocalization in filtered_low_oligo clusters')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_clusters(df_interactions_filtered_low_oligo_clusters, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target clusters\\nthat also contain columns targets'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[0]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[0])\n",
    "    axs[0].set(title='Cluster count normalization')\n",
    "    axs[0].tick_params(labelsize='xx-small')\n",
    "    sns.heatmap(\n",
    "        data=np.log10(normalize_by_pairwise(df_interactions_filtered_low_oligo_pairwise, pseudocount='min_over_ten')),\n",
    "        cbar_kws=dict(label='log10 proportion of row target colocalizations\\ninvolving columns target'),\n",
    "        cbar_ax=mpl_toolkits.axes_grid1.make_axes_locatable(axs[1]).append_axes('right', size='5%', pad=0.05),\n",
    "        square=True,\n",
    "        xticklabels=True, yticklabels=True,\n",
    "        ax=axs[1])\n",
    "    axs[1].set(title='Pairwise count normalization')\n",
    "    axs[1].tick_params(labelsize='xx-small')\n",
    "    fig.savefig(figs_out('interactions_filtered_low_oligo'), bbox_inches='tight')\n",
    "    fig.show()\n",
    "else:\n",
    "    display(Image(filename=figs_out('interactions_filtered_low_oligo')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chipdip_qc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
