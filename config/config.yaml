# Except for conda_env, paths in this file are specified relative to the working directory, which refers to following,
# in order of precedence:
# 1. the directory specified by the `--directory` command line option
# 2. the directory specified by the `workdir:` directive in the Snakefile
# 3. the directory in which Snakemake is invoked

# ==============================================================================
# MODE CONFIGURATION
# ==============================================================================

# Sequencing mode: single-end vs paired-end
# - false: Single-end sequencing (only R1 files used)
# - true: Paired-end sequencing (R1 and R2 files required in samples JSON)
paired_end: false

# Barcode identification tool
# - "barcodeidentification": Use BarcodeIdentification.jar (requires Trim Galore preprocessing)
# - "splitcode": Use splitcode (handles trimming internally)
barcode_tool: "barcodeidentification"

# ==============================================================================
# BARCODE CONFIGURATION - BarcodeIdentification.jar
# (Required when barcode_tool: "barcodeidentification")
# ==============================================================================

# Path to barcode config file (bID format)
barcode_config: "config/example_config.txt"

# Path to barcode format file; set to null or "" to skip barcode validation
barcode_format: "config/example_format.txt"

# Files for cutadapt (used with BarcodeIdentification.jar)
cutadapt_dpm: "resources/dpm96.fasta"
cutadapt_oligos: "resources/bpm.fasta"

# Bead oligo UMI length (used with BarcodeIdentification.jar)
bead_umi_length: 8

# ==============================================================================
# BARCODE CONFIGURATION - splitcode
# (Required when barcode_tool: "splitcode")
# ==============================================================================

# Path to splitcode config files (TSV format)
splitcode-configs:
    split-bpm-dpm: "config/splitcode-config_split-bpm-dpm.tsv"
    oligo: "config/splitcode-config_oligo.tsv"
    chromatin: "config/splitcode-config_chromatin.tsv"

# Number of tags expected: [R1 tags, R2 tags, both orientations]
num_tags_oligo: [3, 7, 3]
num_tags_chromatin: [1, 7, 1]

# ==============================================================================
# SAMPLES AND PATHS
# ==============================================================================

# Email to which errors will be sent; set to null or "" to skip emails
email: ""

# (Required) Path to samples JSON file, e.g., as produced with the fastq2json.py script
# Format for single-end:  {"sample1": {"R1": ["path/to/r1.fastq.gz"]}}
# Format for paired-end:  {"sample1": {"R1": ["path/to/r1.fastq.gz"], "R2": ["path/to/r2.fastq.gz"]}}
samples: "config/example_samples.json"

# (Required) Scripts directory
scripts_dir: "workflow/scripts/"

# Output directory
output_dir: "results"

# Temporary directory
temp_dir: "/tmp"

# Conda environment: either a path to a conda environment YAML file ("*.yml" or "*.yaml")
# or the name of an existing conda environment.
# - If a relative path is used, the path is interpreted as relative to the Snakefile.
# - Alternatively, an absolute path can be used.
conda_env: "envs/chipdip.yaml"

# ==============================================================================
# ALIGNMENT AND FILTERING
# ==============================================================================

# Path to chromosome name map file; set to null or "" to skip chromosome renaming and filtering
path_chrom_map: "config/chrom_map.txt"

# Chromatin reads deduplication method - usually one of the following:
# - "RT&start&end": deduplicate by DPM and read alignment start and end position
# - "RT&start|RT&end": deduplicate by (DPM and read alignment start) or (DPM and end position)
# - "RT&start": deduplicate by DPM and read alignment start position
# - "RT&end": deduplicate by DPM and read alignment end position
deduplication_method: "RT&start&end"

# Number of chunks to split FASTQ reads into for parallel processing
num_chunks: 2

# Mask used for filtering DNA reads
# e.g., "resources/blacklist_mm10.bed" or "resources/blacklist_hg38.bed"
# Set to null or "" to skip filtering
mask: "resources/blacklist_mm10.bed"

# (Required) Bowtie2 indexes for aligning DNA reads
# e.g., "resources/index_hg38/GRCh38_noalt_as" or "resources/index_mm10/mm10"
bowtie2_index: "resources/index_mm10/mm10"

# Maximum insert size for paired-end alignment (bowtie2 --maxins parameter)
# Only used when paired_end: true
bowtie2_max_insert_size: 2500

# ==============================================================================
# OUTPUT OPTIONS
# ==============================================================================

# Merge cluster files for all samples
# Merge BAM files and bigWigs for individual targets across samples
merge_samples: true

# Generate BAM files for individual targets
generate_splitbams: true
min_oligos: 2
proportion: 0.8
max_size: 10000

# bigWig generation parameters
# - only relevant if generate_splitbams is True
# - binsize: bin size in bp
#   - Set to false to skip bigWig generation
# - bigwig_normalization: "RPKM", "CPM", "BPM", "RPGC", or "None"
#   - Passed to the --normalizeUsing argument for bamCoverage from the deepTools suite
# - effective_genome_size: effective genome size in bp
#   - only relevant if bigwig_normalization is "RPGC"
#   - Supply as an integer, or set to null for the pipeline to compute the effective genome size
#     based on the Bowtie2 index, mask, and chromosome name map
binsize: 1000
bigwig_normalization: "None"
effective_genome_size: null
